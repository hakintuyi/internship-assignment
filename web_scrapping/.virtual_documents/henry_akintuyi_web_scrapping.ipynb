import requests
from bs4 import BeautifulSoup
import pandas as pd
import nltk
from tqdm import tqdm
from nltk.tokenize import sent_tokenize




url = "https://www.gutenberg.org/files/11/11-h/11-h.htm"
page = requests.get(url)
soup = BeautifulSoup(page.text, "html")


print(soup)



# Find all chapters
chapters = soup.find_all('div', class_='chapter')


# Get only the first chapter
if chapters:
    first_chapter_text = chapters[0].text
    print(first_chapter_text)



if chapters:
    first_chapter_text = chapters[0].text
    df = pd.DataFrame({'Chapter_Text': [first_chapter_text]})
    df.to_csv('first_chapter.csv', index=False)
else:
    print("No chapters found.")






